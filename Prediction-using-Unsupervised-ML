import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.cluster import KMeans
from sklearn import datasets

# Load the Iris dataset from sklearn datasets
iris = datasets.load_iris()
iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)

# Display the first few rows of the dataset
print(iris_df.head())

# Extract the features (sepal length, sepal width, petal length, petal width)
x = iris_df.iloc[:, [0, 1, 2, 3]].values

# Determine the optimum number of clusters using the elbow method
wcss = []
for i in range(1, 11):
    kmeans = KMeans(n_clusters=i, init="k-means++", max_iter=300, n_init=10, random_state=0)
    kmeans.fit(x)
    wcss.append(kmeans.inertia_)

# Plotting the elbow curve to visualize the optimum number of clusters
plt.plot(range(1, 11), wcss)
plt.title("The Elbow Method")
plt.xlabel("Number of Clusters")
plt.ylabel("WCSS")  # Within Cluster Sum of Squares
plt.show()

# Apply K-means clustering with the chosen number of clusters (3 in this case)
kmeans = KMeans(n_clusters=3, init="k-means++", max_iter=300, n_init=10, random_state=0)
y_kmeans = kmeans.fit_predict(x)

# Visualize the clusters based on the first two columns (sepal length and sepal width)
plt.scatter(x[y_kmeans == 0, 0], x[y_kmeans == 0, 1], 
            s=100, c='red', label='Iris-setosa')
plt.scatter(x[y_kmeans == 1, 0], x[y_kmeans == 1, 1], 
            s=100, c='blue', label='Iris-versicolour')
plt.scatter(x[y_kmeans == 2, 0], x[y_kmeans == 2, 1],
            s=100, c='green', label='Iris-virginica')

# Plotting the centroids of the clusters
plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], 
            s=100, c='yellow', label='Centroids')

plt.legend()
plt.show()
